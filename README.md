# gradient-descent

<h3>Linear Regression implementation using gradient descent.</h3>

In statistics, linear regression is a linear approach to modelling the relationship between a dependent variable and one or more independent variables. 

<h3>Loss Function</h3>

The loss is the error in our predicted value of slope and intercept. Our goal is to minimize this error to obtain the most accurate value of slope and intercept.
We will use the Mean Squared Error function to calculate the loss.

<h3>The Learning rate</h3>

This size of steps taken to reach the minimum or bottom is called Learning Rate. We can cover more area with larger steps/higher learning rate but are at the risk of overshooting the minima. On the other hand, small steps/smaller learning rates will consume a lot of time to reach the lowest point.

<h3>Derivatives</h3>

Machine learning uses derivatives in optimization problems. Optimization algorithms like gradient descent use derivates to actually decide whether to increase or decrease the weights in order to increase or decrease any objective function.
